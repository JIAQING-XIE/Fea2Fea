{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_file = pd.read_csv('geometric_graph_200_property.txt', sep = '\\t')\n",
    "edge_idx_file = pd.read_csv('geometric_graph_200_edge_idx.txt', sep = ',',header = None)\n",
    "\n",
    "x = torch.tensor(np.array(property_file), dtype=torch.float)\n",
    "edge_idx = torch.tensor(np.array(edge_idx_file), dtype=torch.long)\n",
    "y = torch.tensor([[1] for i in range(200)])\n",
    "#print(edge_idx)\n",
    "data = Data(x=x, edge_index=edge_idx.t().contiguous(), y =y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 55, 158, 132, 126, 124,  87, 163,  98,  76, 152, 192, 169, 138,   7,\n",
      "        150,  83, 191, 121, 140,  62,  47,  41,  13, 196, 120,   8,  40,  46,\n",
      "        123, 171, 103, 195, 193, 145,  89, 165, 114, 184,  38,  52,  75, 129,\n",
      "        182,  88,  67, 143,  50,  77, 136, 110,  66,  16, 173,  70, 137,  42,\n",
      "         11, 162, 194,  71, 172,  45,  14,  44, 175, 100, 128, 167,  28, 160,\n",
      "         35,  26, 161, 104,  48, 134, 108, 154, 112,  18, 149, 111, 148,  74,\n",
      "        186,  59, 125,  43, 166, 180, 142, 159,  19, 127,  86,  73, 178,  49,\n",
      "        106,  21,  22,  27, 117,  34,   1, 118, 156,   6,  93, 176,  17,  51,\n",
      "         80,   4,  72,  57,  64, 179,  68,  30])\n",
      "tensor([188,  12, 113,  33,  96,  65,  25, 197,  32, 198, 139,  15,  56,  91,\n",
      "          3,  97, 181, 155,   5, 115, 116, 144, 168, 190, 122,  99, 135,   2,\n",
      "         36,  94])\n"
     ]
    }
   ],
   "source": [
    "num_nodes = 200\n",
    "num_train_nodes = 120\n",
    "num_valid_nodes = 30\n",
    "num_test_nodes = 30\n",
    "perm = torch.randperm(num_nodes)\n",
    "train_idx = perm[:num_train_nodes]\n",
    "valid_idx = perm[num_train_nodes:(num_train_nodes+num_valid_nodes)]\n",
    "test_dix = perm[(num_train_nodes+num_valid_nodes):(num_train_nodes+num_valid_nodes+num_test_nodes)]\n",
    "\n",
    "## debugging\n",
    "#print(train_idx)\n",
    "#print(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(5, 256)\n",
    "        self.conv2 = GCNConv(256,64)\n",
    "        \n",
    "        self.linear1 = nn.Linear(64,16)\n",
    "        self.linear2 = nn.Linear(16, 6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "\n",
    "def train(data, train_idx):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[train_idx], data.y[train_idx])\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /opt/conda/conda-bld/pytorch_1607369981906/work/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-bdbac936f9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-81-30464a323119>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, train_idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /opt/conda/conda-bld/pytorch_1607369981906/work/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    train(data,train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os.path as osp\n",
    "path = osp.join('/home/jiaqing/桌面/Fea2Fea/data/')\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model(data)[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(data), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "#------------------ Start our algorithm1 ---------------------#\n",
    "if __name__ == '__main__':\n",
    "    xlabels = ['Constant','Degree','Clustering_Coefficient','PageRank','Aver_Path_Len']\n",
    "    for dataset,embedding_method in list(itertools.product(['Cora','PubMed','Citeseer'],['SAGE','GAT','GCN','GIN'])):\n",
    "        \n",
    "        Aver = np.zeros((5,5))\n",
    "        dataset_name = dataset\n",
    "        dataset = Planetoid(path, name = dataset, transform=T.NormalizeFeatures())\n",
    "        data = dataset[0]\n",
    "\n",
    "        name = r'/home/jiaqing/桌面/Fea2Fea/Result/Planetoid/' + dataset_name + '_property.txt'\n",
    "        property_file = pd.read_csv(name, sep = '\\t')\n",
    "        \n",
    "        \n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        best_val_acc = test_acc = 0\n",
    "        t = 0\n",
    "        record_acc = 1\n",
    "        total_epoch = 0 # for drawing curves\n",
    "        avg_num = 10 # for iteration to count average accuracy\n",
    "        \n",
    "        for avg in range(avg_num):\n",
    "            R = np.zeros((5,5)) # initialize our feature relationship matrix \n",
    "            R[0][0] = 1.000\n",
    "            for i in range(2, 5):\n",
    "                propert_i = property_file.iloc[:,[i]]\n",
    "                array = np.array(propert_i)\n",
    "                data.x = torch.tensor(array).float()\n",
    "                for j in range(1,5):\n",
    "                    propert_j = property_file.iloc[:,[j]]\n",
    "                    array_2 = np.array(propert_j)\n",
    "                    number = len(data.y)\n",
    "                    data.y = binning(array_2, k = 6,data_len =  number)\n",
    "                    \n",
    "                    model =  Net(embedding=embedding_method).to(device) if embedding_method != 'MLP' else debug_MLP().to(device)\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=1e-4)\n",
    "                    #scheduler = StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "                    data =  data.to(device)\n",
    "                    t = 0\n",
    "                    best_val_acc = test_acc = 0 \n",
    "                    for epoch in range(1, 2000):\n",
    "                        \n",
    "                        train()\n",
    "                        train_acc, val_acc, tmp_test_acc = test()\n",
    "\n",
    "                        if val_acc > best_val_acc:\n",
    "                            best_val_acc = val_acc\n",
    "                            test_acc = tmp_test_acc\n",
    "                            if i == 0:\n",
    "                                R[i][j] = round(test_acc,3)\n",
    "                                R[j][i] = round(test_acc,3)\n",
    "                            else:\n",
    "                                R[i][j] = round(test_acc,3)\n",
    "                            t = 0\n",
    "                        t = t + 1\n",
    "                        if t > 500:\n",
    "                            break   \n",
    "                        \n",
    "                        log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "                        print(log.format(epoch, train_acc, best_val_acc, test_acc))\n",
    "                        # do that for several times\n",
    "                        #scheduler.step()\n",
    "                    if i == 4 and j == 4:\n",
    "                        Aver = Aver + R\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook, we are going to show you the embeddings before and after training,\n",
    "## including the initial embed(before graph embed), graph embed(before MLP) and MLP embed(before output)\n",
    "\n",
    "### You can also run tSNE_citation.py under the same folder \n",
    "### If you want to test on graph datasets, you can also run tSNE_tudataset.py \n",
    "### Ideally you do not need to add command line parameters since the program will generate results on given test cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "import statistics\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from optimal_R import option, all_possible_concatenation\n",
    "from graph_property import G_property, binning\n",
    "from model.GNN import Net, debug_MLP\n",
    "from utils import max_len_arr\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model(data)[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(data), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "      0    1    2    3    4\n",
      "0  SAGE  GIN  GIN  GIN  GCN\n",
      "1   GIN  GIN  GCN  GIN  GIN\n",
      "2   GIN  GIN  MLP  GIN  GCN\n",
      "3   GIN  GIN  GIN  GIN  GIN\n",
      "4   GCN  GIN  GIN  GIN  MLP\n",
      "GIN\n",
      "Epoch: 001, Train: 0.3929, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 002, Train: 0.2071, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 003, Train: 0.3429, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 004, Train: 0.3786, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 005, Train: 0.4143, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 006, Train: 0.4143, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 007, Train: 0.4429, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 008, Train: 0.4571, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 009, Train: 0.4714, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 010, Train: 0.5000, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 011, Train: 0.5000, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 012, Train: 0.5000, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 013, Train: 0.4857, Val: 0.4720, Test: 0.4610\n",
      "Epoch: 014, Train: 0.4714, Val: 0.4820, Test: 0.4600\n",
      "Epoch: 015, Train: 0.4929, Val: 0.4920, Test: 0.4620\n",
      "Epoch: 016, Train: 0.5000, Val: 0.4960, Test: 0.4650\n",
      "Epoch: 017, Train: 0.5286, Val: 0.5080, Test: 0.4910\n",
      "Epoch: 018, Train: 0.5571, Val: 0.5180, Test: 0.5010\n",
      "Epoch: 019, Train: 0.5714, Val: 0.5280, Test: 0.5130\n",
      "Epoch: 020, Train: 0.5571, Val: 0.5360, Test: 0.5270\n",
      "Epoch: 021, Train: 0.5571, Val: 0.5380, Test: 0.5290\n",
      "Epoch: 022, Train: 0.5714, Val: 0.5380, Test: 0.5290\n",
      "Epoch: 023, Train: 0.5571, Val: 0.5380, Test: 0.5290\n",
      "Epoch: 024, Train: 0.5643, Val: 0.5380, Test: 0.5290\n",
      "Epoch: 025, Train: 0.5714, Val: 0.5380, Test: 0.5290\n",
      "Epoch: 026, Train: 0.5357, Val: 0.5380, Test: 0.5290\n",
      "Epoch: 027, Train: 0.5429, Val: 0.5380, Test: 0.5290\n",
      "Epoch: 028, Train: 0.5714, Val: 0.5400, Test: 0.5270\n",
      "Epoch: 029, Train: 0.5643, Val: 0.5420, Test: 0.5260\n",
      "Epoch: 030, Train: 0.5643, Val: 0.5480, Test: 0.5350\n",
      "Epoch: 031, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 032, Train: 0.5643, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 033, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 034, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 035, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 036, Train: 0.5500, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 037, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 038, Train: 0.5500, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 039, Train: 0.5143, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 040, Train: 0.4929, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 041, Train: 0.4929, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 042, Train: 0.4857, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 043, Train: 0.4714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 044, Train: 0.4714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 045, Train: 0.4857, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 046, Train: 0.4786, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 047, Train: 0.4857, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 048, Train: 0.4857, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 049, Train: 0.4929, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 050, Train: 0.5071, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 051, Train: 0.4929, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 052, Train: 0.5000, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 053, Train: 0.4857, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 054, Train: 0.4714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 055, Train: 0.4643, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 056, Train: 0.4786, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 057, Train: 0.5071, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 058, Train: 0.5214, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 059, Train: 0.5286, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 060, Train: 0.5286, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 061, Train: 0.5286, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 062, Train: 0.5286, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 063, Train: 0.5286, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 064, Train: 0.5000, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 065, Train: 0.4929, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 066, Train: 0.4786, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 067, Train: 0.4643, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 068, Train: 0.4857, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 069, Train: 0.5000, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 070, Train: 0.4929, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 071, Train: 0.4714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 072, Train: 0.4786, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 073, Train: 0.4714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 074, Train: 0.4714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 075, Train: 0.4786, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 076, Train: 0.4929, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 077, Train: 0.5214, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 078, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 079, Train: 0.5643, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 080, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 081, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 082, Train: 0.5429, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 083, Train: 0.5286, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 084, Train: 0.5357, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 085, Train: 0.5500, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 086, Train: 0.5857, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 087, Train: 0.5786, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 088, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 089, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 090, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 091, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 092, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 093, Train: 0.5786, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 094, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 095, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 096, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 097, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 098, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 099, Train: 0.5643, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 100, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 101, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 102, Train: 0.5643, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 103, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 104, Train: 0.5643, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 105, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 106, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 107, Train: 0.5714, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 108, Train: 0.5786, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 109, Train: 0.5857, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 110, Train: 0.5857, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 111, Train: 0.5643, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 112, Train: 0.5571, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 113, Train: 0.5643, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 114, Train: 0.6000, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 115, Train: 0.6000, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 116, Train: 0.6000, Val: 0.5560, Test: 0.5500\n",
      "Epoch: 117, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 118, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 119, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 120, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 121, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 122, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 123, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 124, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 125, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 126, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 127, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 128, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 129, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 130, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 131, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 132, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 133, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 134, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 135, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 136, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 137, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 138, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 139, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 140, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 141, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 142, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 143, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 144, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 145, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 146, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 147, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 148, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 149, Train: 0.5286, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 150, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 151, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 152, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 153, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 154, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 155, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 156, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 157, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 158, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 159, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 160, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 161, Train: 0.5429, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 162, Train: 0.5357, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 163, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 164, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 165, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 166, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 167, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 168, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 169, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 170, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 171, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 172, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 173, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 174, Train: 0.5286, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 175, Train: 0.5357, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 176, Train: 0.5429, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 177, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 178, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 179, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 180, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 181, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 182, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 183, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 184, Train: 0.5643, Val: 0.5600, Test: 0.5330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 186, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 187, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 188, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 189, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 190, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 191, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 192, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 193, Train: 0.6214, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 194, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 195, Train: 0.5357, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 196, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 197, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 198, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 199, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 200, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 201, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 202, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 203, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 204, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 205, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 206, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 207, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 208, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 209, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 210, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 211, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 212, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 213, Train: 0.5286, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 214, Train: 0.5357, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 215, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 216, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 217, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 218, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 219, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 220, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 221, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 222, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 223, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 224, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 225, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 226, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 227, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 228, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 229, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 230, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 231, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 232, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 233, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 234, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 235, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 236, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 237, Train: 0.5286, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 238, Train: 0.5357, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 239, Train: 0.5357, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 240, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 241, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 242, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 243, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 244, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 245, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 246, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 247, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 248, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 249, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 250, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 251, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 252, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 253, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 254, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 255, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 256, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 257, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 258, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 259, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 260, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 261, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 262, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 263, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 264, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 265, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 266, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 267, Train: 0.6071, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 268, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 269, Train: 0.6214, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 270, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 271, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 272, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 273, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 274, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 275, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 276, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 277, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 278, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 279, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 280, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 281, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 282, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 283, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 284, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 285, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 286, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 287, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 288, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 289, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 290, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 291, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 292, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 293, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 294, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 295, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 296, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 297, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 298, Train: 0.5429, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 299, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 300, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 301, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 302, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 303, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 304, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 305, Train: 0.6071, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 306, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 307, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 308, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 309, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 310, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 311, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 312, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 313, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 314, Train: 0.6143, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 315, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 316, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 317, Train: 0.5357, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 318, Train: 0.5286, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 319, Train: 0.5357, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 320, Train: 0.5286, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 321, Train: 0.5286, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 322, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 323, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 324, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 325, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 326, Train: 0.5286, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 327, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 328, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 329, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 330, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 331, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 332, Train: 0.5357, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 333, Train: 0.4429, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 334, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 335, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 336, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 337, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 338, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 339, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 340, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 341, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 342, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 343, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 344, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 345, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 346, Train: 0.5571, Val: 0.5600, Test: 0.5330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 347, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 348, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 349, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 350, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 351, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 352, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 353, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 354, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 355, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 356, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 357, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 358, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 359, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 360, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 361, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 362, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 363, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 364, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 365, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 366, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 367, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 368, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 369, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 370, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 371, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 372, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 373, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 374, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 375, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 376, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 377, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 378, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 379, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 380, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 381, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 382, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 383, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 384, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 385, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 386, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 387, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 388, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 389, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 390, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 391, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 392, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 393, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 394, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 395, Train: 0.5429, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 396, Train: 0.5429, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 397, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 398, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 399, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 400, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 401, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 402, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 403, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 404, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 405, Train: 0.6143, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 406, Train: 0.6071, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 407, Train: 0.6071, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 408, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 409, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 410, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 411, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 412, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 413, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 414, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 415, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 416, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 417, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 418, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 419, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 420, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 421, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 422, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 423, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 424, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 425, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 426, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 427, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 428, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 429, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 430, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 431, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 432, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 433, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 434, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 435, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 436, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 437, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 438, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 439, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 440, Train: 0.5429, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 441, Train: 0.5429, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 442, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 443, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 444, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 445, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 446, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 447, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 448, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 449, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 450, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 451, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 452, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 453, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 454, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 455, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 456, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 457, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 458, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 459, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 460, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 461, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 462, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 463, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 464, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 465, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 466, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 467, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 468, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 469, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 470, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 471, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 472, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 473, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 474, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 475, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 476, Train: 0.5357, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 477, Train: 0.5500, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 478, Train: 0.5429, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 479, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 480, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 481, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 482, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 483, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 484, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 485, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 486, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 487, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 488, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 489, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 490, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 491, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 492, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 493, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 494, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 495, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 496, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 497, Train: 0.5571, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 498, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 499, Train: 0.5714, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 500, Train: 0.5643, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 501, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 502, Train: 0.5786, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 503, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 504, Train: 0.5857, Val: 0.5600, Test: 0.5330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 505, Train: 0.6071, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 506, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 507, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 508, Train: 0.5857, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 509, Train: 0.6000, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 510, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 511, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 512, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 513, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 514, Train: 0.5929, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 515, Train: 0.6143, Val: 0.5600, Test: 0.5330\n",
      "Epoch: 516, Train: 0.5857, Val: 0.5600, Test: 0.5330\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-427a60bb797b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# draw tSNE pictures here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m#y = np.array(property_j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "path = osp.join('/home/jiaqing/桌面/Fea2Fea/data/')\n",
    "test_case = [(2, 1),(1, 3)]\n",
    "\n",
    "dataset_name = ['Cora', 'PubMed', 'Citeseer']\n",
    "for dataset in dataset_name:\n",
    "    d_name = dataset\n",
    "    dataset = Planetoid(path, name = dataset, transform=T.NormalizeFeatures())\n",
    "    data = dataset[0]\n",
    "    path = r'/home/jiaqing/桌面/Fea2Fea/Result/Planetoid/'\n",
    "    name = path + d_name + '_property.txt'\n",
    "    property_file = pd.read_csv(name, sep = '\\t')\n",
    "    for (j, i) in test_case:\n",
    "        print(i,j)\n",
    "        # find optimal graph embedding method according to each\n",
    "        # input graph feature and output graph feature\n",
    "        tmp_txt = pd.read_csv(path + d_name + '_optimal_method.txt', sep = '\\t', header = None) # array\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        embedding = 0\n",
    "        best_val_acc = test_acc = 0\n",
    "        t = 0\n",
    "        train_accu_plot = []\n",
    "        epoch_plot = []\n",
    "        print(tmp_txt)\n",
    "        print(tmp_txt[1][2])\n",
    "        # take the optimal embedding method as graph embedding\n",
    "        model = Net(embedding=tmp_txt[i][j]).to(device) if tmp_txt[i][j] != 'MLP' else debug_MLP().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=5e-4)\n",
    "\n",
    "        property_i = np.array(property_file.iloc[:,[i]])\n",
    "        data.x = torch.tensor(property_i).float()\n",
    "\n",
    "        property_j = np.array(property_file.iloc[:,[j]])\n",
    "        tmp = binning(property_j, k = 6, data_len = len(data.y))\n",
    "        data.y = binning(property_j, k = 6, data_len = len(data.y))\n",
    "        data =  data.to(device)\n",
    "        for epoch in range(1, 3000):   \n",
    "            train()\n",
    "            train_acc, val_acc, tmp_test_acc = test()\n",
    "            #train_accu_plot.append(train_acc)\n",
    "            #epoch_plot.append(epoch)\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                test_acc = tmp_test_acc\n",
    "                embedding = model.latent\n",
    "                t = 0\n",
    "            t = t + 1\n",
    "            if t > 400:\n",
    "                break   \n",
    "            log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "            print(log.format(epoch, train_acc, best_val_acc, test_acc))\n",
    "\n",
    "        nb_classes = 6\n",
    "        confusion_matrix = torch.zeros(nb_classes,nb_classes)\n",
    "        pre_comb = torch.tensor([])\n",
    "        real_comb = torch.tensor([])\n",
    "\n",
    "        '''\n",
    "        #----- print macro-f1 score\n",
    "        with torch.no_grad():\n",
    "            logits, accs = model(), []\n",
    "            for _, mask in data('test_mask'):\n",
    "                pred = logits[mask].max(1)[1]\n",
    "                pre_comb = torch.cat((pre_comb, pred), 0)\n",
    "                real_comb = torch.cat((real_comb, data.y[mask]), 0)\n",
    "\n",
    "                #print(pred)\n",
    "                #print(data.y[mask])\n",
    "                for i in range(len(pred)):\n",
    "                    confusion_matrix[pred[i]][data.y[mask][i]] = confusion_matrix[pred[i]][data.y[mask][i]]+1\n",
    "            print(confusion_matrix)#\n",
    "            print(f1_score(pre_comb.numpy(), real_comb.numpy(), average='macro'))\n",
    "        '''\n",
    "\n",
    "        # draw tSNE pictures here:\n",
    "        x = embedding.detach().numpy()\n",
    "        #y = np.array(property_j)\n",
    "        X_tsne = TSNE(n_components=2,random_state=33).fit_transform(x)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        ax = plt.subplot(1,1,1,)\n",
    "\n",
    "        values = range(6)\n",
    "        cNorm  = colors.Normalize(vmin=0, vmax=values[-1])\n",
    "        scaMap = plt.cm.ScalarMappable(norm = cNorm  ,cmap = \"coolwarm\")\n",
    "\n",
    "        for k in range(6):  \n",
    "            colorval = scaMap.to_rgba(values[k])\n",
    "            ax.scatter(X_tsne[np.where(tmp.numpy() == k), 0], X_tsne[np.where(tmp.numpy() == k), 1] ,label = k, s =3, color = colorval)\n",
    "\n",
    "\n",
    "        handles,labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles, labels, loc='upper right',fontsize = 7)\n",
    "        plt.xlabel(\"tSNE 1\",fontsize = 12)\n",
    "        plt.ylabel(\"tSNE 2\", fontsize = 12)\n",
    "        plt.tick_params(labelsize=12)\n",
    "        name2 = r'/home/jiaqing/桌面/FASG_KDD/Result/tSNE/'\n",
    "        plt.savefig(name2 + str(d_name)+\"_\"+ str(i)+ \"to\" + str(j) +\"_tSNE.eps\", dpi = 800, format = 'eps')\n",
    "        #plt.show()\n",
    "        #plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=tmp.numpy(), cmap = \"rainbow\")\n",
    "        #plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
